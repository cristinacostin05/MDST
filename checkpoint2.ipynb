{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Checkpoint:</h1>\n",
    "\n",
    "**Looking to see completetion and effort in completing the checkpoint. It's okay if it's not correct**\n",
    "\n",
    "Based off this dataset with school financial, enrollment, and achievement data, we are interested in what information is a useful indicator of student performance at the state level.\n",
    "\n",
    "This question is a bit too big for a checkpoint, however. Instead, we want you to look at smaller questions related to our overall goal. Here's the overview:\n",
    "\n",
    "1. Choose a specific test to focus on\n",
    ">Math/Reading for 4/8 grade\n",
    "* Pick or create features to use\n",
    ">Will all the features be useful in predicting test score? Are some more important than others? Should you standardize, bin, or scale the data?\n",
    "* Explore the data as it relates to that test\n",
    ">Create 2 well-labeled visualizations (graphs), each with a caption describing the graph and what it tells us about the data\n",
    "* Create training and testing data\n",
    ">Do you want to train on all the data? Only data from the last 10 years? Only Michigan data?\n",
    "* Train a ML model to predict outcome \n",
    ">Pick if you want to do a regression or classification task. For both cases, defined _exactly_ what you want to predict, and pick any model in sklearn to use (see sklearn <a href=\"https://scikit-learn.org/stable/modules/linear_model.html\">regressors</a> and <a href=\"https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\">classifiers</a>).\n",
    "* Summarize your findings\n",
    ">Write a 1 paragraph summary of what you did and make a recommendation about if and how student performance can be predicted\n",
    "\n",
    "** Include comments throughout your code! Every cleanup and preprocessing task should be documented.\n",
    "\n",
    "\n",
    "Of course, if you're finding this assignment interesting (and we really hope you do!), you are welcome to do more than the requirements! For example, you may want to see if expenditure affects 4th graders more than 8th graders. Maybe you want to look into the extended version of this dataset and see how factors like sex and race are involved. You can include all your work in this notebook when you turn it in -- just always make sure you explain what you did and interpret your results. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Cleanup </h2>\n",
    "\n",
    "Import numpy, pandas, matplotlib, and seaborn\n",
    "\n",
    "(Feel free to import other libraries!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the \"states_edu.csv\" dataset and take a look at the head of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Desktop/mdst_tutorials_W22/data/states_edu.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should always familiarize yourself with what each column in the dataframe represents. \\ Read about the states_edu dataset here: https://www.kaggle.com/noriuk/us-education-datasets-unification-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this space to rename columns, deal with missing data, etc. _(optional)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exploratory Data Analysis (EDA) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen Outcome Variable for Test: **<Math/Reading for 4/8 grade>**   (Ex. Math for 8th grade)\n",
    "\n",
    "**(hit `Enter` to edit)**\n",
    "\n",
    "Outcome Score in the questions refers to the outcome variable you chose here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different years of data are in our dataset? Use a pandas function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of valid years \n",
    "df.count()\n",
    "# remove rows with missing values\n",
    "df.dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare Michigan to Ohio. Which state has the higher average outcome score across all years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int michigan = df[subset = ['GRADES_ALL_G'], 'MICHIGAN')]\n",
    "int ohio = df[subset = ['GRADES_ALL_G'], 'OHIO')]\n",
    "String winner\n",
    "if(michigan > ohio){\n",
    "    winner = \"Michigan\"\n",
    "}else{\n",
    "    winner = \"Ohio\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the average for your outcome score across all states in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int avg_all_outcomes = df.count(['GRADES_ALL_G'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the maximum outcome score for every state. Hint: there's a function that allows you to do this easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int max_all_outcomes = df.count(['GRADES_ALL_G']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature Selection </h2>\n",
    "\n",
    "After exploring the data, you now have to choose features that you would use to predict the performance of the students on a chosen test (chosen outcome variable). By the way, you can also create your own features. For example, perhaps you figured that maybe a state's expenditure per student may affect their overall academic performance so you create a expenditure_per_student feature.\n",
    "\n",
    "Use this space to modify or create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FEDERAL_REVENUE_PER_STUDENT'] = df['FEDERAL_REVENUE']/ df['ENROLL']\n",
    "df['LOCAL_REVENUE_PER_STUDENT'] = df['LOCAL_REVENUE']/ df['ENROLL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final feature list: **<LIST FEATURES HERE\\>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Federal Revenue Per Student\n",
    "Local Revenue Per Student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection justification: **<BRIEFLY DESCRIBE WHY YOU PICKED THESE FEATURES\\>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I chose these features because I think it would be interesting to see how a performance changes according to the differences between federal revenue and local revenue and to see if there is a correlation between the two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualization</h2>\n",
    "\n",
    "Use any graph you wish to see the relationship of your chosen outcome variable with any features you chose\n",
    "\n",
    "**Visualization 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.GRADES_ALL_G.hist()\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of socres of all classes between all grades')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<CAPTION FOR VIZ 1>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distribution of socres of all classes between all grades "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('STATE').GRADES_ALL_G.mean().plot()\n",
    "plt.ylabel('SCORE')\n",
    "plt.title('All Grades in all Classes organized by State')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<CAPTION FOR VIZ 2>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All Grades in all Classes organized by State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Creation </h2>\n",
    "\n",
    "_Use this space to create train/test data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['FEDERAL_REVENUE', 'ALL_GRADES_G', 'FEDERAL_REVENUE_PER_STUDENT', 'YEAR']].dropna()\n",
    "y = df.loc[X.index]['ALL_GRADES_G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prediction </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Models Resource: https://medium.com/@vijaya.beeravalli/comparison-of-machine-learning-classification-models-for-credit-card-default-data-c3cf805c9a5a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen ML task: **<REGRESSION/CLASSIFICATION>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your sklearn class here\n",
    "from sklearn.model_selection import train_test_spit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your model here\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR CLASSIFICATION ONLY:\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test,\n",
    "                         cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR REGRESSION ONLY: (pick a single column to visualize results)\n",
    "\n",
    "# Results from this graph _should not_ be used as a part of your results -- it is just here to help with intuition. \n",
    "# Instead, look at the error values and individual intercepts.\n",
    "\n",
    "\n",
    "col_name = 'TOTAL_FEDERAL_REVENUE'\n",
    "col_index = X_train.columns.get_loc(col_name)\n",
    "\n",
    "f = plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_train[col_name], y_train, color = \"red\")\n",
    "plt.scatter(X_train[col_name], model.predict(X_train), color = \"green\")\n",
    "plt.scatter(X_test[col_name], model.predict(X_test), color = \"blue\")\n",
    "\n",
    "new_x = np.linspace(X_train[col_name].min(),X_train[col_name].max(),200)\n",
    "intercept = model.predict([X_train.sort_values(col_name).iloc[0]]) - X_train[col_name].min()*model.coef_[col_index]\n",
    "plt.plot(new_x, intercept+new_x*model.coef_[col_index])\n",
    "\n",
    "plt.legend(['controlled model','true training','predicted training','predicted testing'])\n",
    "plt.xlabel(col_name)\n",
    "plt.ylabel('All Grades G')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Summary </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<WRITE A PARAGRAPH SUMMARIZING YOUR WORK AND FINDINGS\\>**\n",
    "\n",
    "Throughout this assignment, I learned about different python libraries and their applications. I also learned how to read real data from an outside website and determined which findings from the study stood out to me and based on what conclusions I drew, I was able to find statistics about those factors, and even create variables of my own based on these. I found it very interesting to compare different states and what factors affected their school performance. I personally found how federal revenue affected a schools performance was very interesting. It was very intuitive to see these factors and their correlations on the graphs I was able to make. Lastly, I learned about machiene learning for the first time which was very interesting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
